{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About As part of the CANARI project (Climate change in the Arctic \u2013 North Atlantic region and impacts on the UK) a large ensemble of the HadGEM3 coupled climate model is being run, CANARI-LE . Following the success of the data analysis sprint in March 2024 a data has been set for a second sprint, the week of January 27-31, 2025. This page is designed to provide details of the ensemble, information about the data and how to access it , pre-event requirements , sprint , tutorials and frequently asked questions . Highlights from the previous can current sprints can be found on the highlights page. Publications Soon :)","title":"About"},{"location":"#about","text":"As part of the CANARI project (Climate change in the Arctic \u2013 North Atlantic region and impacts on the UK) a large ensemble of the HadGEM3 coupled climate model is being run, CANARI-LE . Following the success of the data analysis sprint in March 2024 a data has been set for a second sprint, the week of January 27-31, 2025. This page is designed to provide details of the ensemble, information about the data and how to access it , pre-event requirements , sprint , tutorials and frequently asked questions . Highlights from the previous can current sprints can be found on the highlights page.","title":"About"},{"location":"#publications","text":"Soon :)","title":"Publications"},{"location":"FAQ/","text":"FAQ Slack How can I access the CANARI Slack workspace? The CANARI Slack workspace can be accessed online here . If you do not yet have an account you can request one by emailing Ben Harvey (b.j.harvey@ncas.ac.uk) or Jenny Mecking (jmecki@noc.ac.uk) directly and they can add you to the CANARI Slack workspace. How do I join channels on Slack? You can see all the channels which already exist in the CANARI Slack workspace by scrolling to the bottom of the list of channels, just before direct messages and there should be an option '+ Add channels'. Clicking on '+ Add channels' will bring up 2 options, choose 'Browse Channels' and you will get a list of all the channels and they will all an option to join them when you hover over them. All channels specific to for the sprint will be labeled 'sprint' and channels specific to ask for help are labeled 'sprint-help'. Can I make my own channel on the CANARI Slack workspace for the sprint? Everyone is welcome to make their own slack channels to help collaborate during the sprint. When creating a new channel specifically for the sprint please name it starting with 'sprint-'. Python Do I have to use python? No, you are not required to use python to do analysis during the sprint. Feel free to use whatever you are familiar with. However, you are limited by what is available on JASMIN. The list of what is available on JASMIN can be found here . How can do I access the Jupiter notebook service on JASMIN? See Configuring and Using the JASMIN Notebooks Service on the Tutorial page. General What should I do if I want to share about the sprint on social media? Please tag @CANARI_Science in you X/Twitter posts. @CANARI_Science will all be tweeting updates throughout the event, please feel free to retweet those as well.","title":"FAQ"},{"location":"FAQ/#faq","text":"","title":"FAQ"},{"location":"FAQ/#slack","text":"How can I access the CANARI Slack workspace? The CANARI Slack workspace can be accessed online here . If you do not yet have an account you can request one by emailing Ben Harvey (b.j.harvey@ncas.ac.uk) or Jenny Mecking (jmecki@noc.ac.uk) directly and they can add you to the CANARI Slack workspace. How do I join channels on Slack? You can see all the channels which already exist in the CANARI Slack workspace by scrolling to the bottom of the list of channels, just before direct messages and there should be an option '+ Add channels'. Clicking on '+ Add channels' will bring up 2 options, choose 'Browse Channels' and you will get a list of all the channels and they will all an option to join them when you hover over them. All channels specific to for the sprint will be labeled 'sprint' and channels specific to ask for help are labeled 'sprint-help'. Can I make my own channel on the CANARI Slack workspace for the sprint? Everyone is welcome to make their own slack channels to help collaborate during the sprint. When creating a new channel specifically for the sprint please name it starting with 'sprint-'.","title":"Slack"},{"location":"FAQ/#python","text":"Do I have to use python? No, you are not required to use python to do analysis during the sprint. Feel free to use whatever you are familiar with. However, you are limited by what is available on JASMIN. The list of what is available on JASMIN can be found here . How can do I access the Jupiter notebook service on JASMIN? See Configuring and Using the JASMIN Notebooks Service on the Tutorial page.","title":"Python"},{"location":"FAQ/#general","text":"What should I do if I want to share about the sprint on social media? Please tag @CANARI_Science in you X/Twitter posts. @CANARI_Science will all be tweeting updates throughout the event, please feel free to retweet those as well.","title":"General"},{"location":"cf_python/","text":"Computing indices with cf-python cf-python is a python Earth Science data analysis library that is built on a complete implementation of the CF data model. It makes reading, writing and processing of cf netcdf data very simple. This tutorial points to some basic examples for use on the CANARI SPRINT data on JASMIN These examples can all be found in /home/users/dlrhodso/CANARI/SPRINT_2024/examples . All sumbit submit multiple jobs in parallel in order to process all ensemble members at once. They use the LOTUS script to do this - this is a wrapper script for the SLURM submission commands that make it very easy to submit jobs and not worry about log files etc. All these scripts use the default JASMIN sci JASPY enviromnet ( module load jaspy ) - but the LOTUS script automatically loads JASPY. Computing a box average NAO index compute_nao.sh loops over all MSLP files in the /gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2 directory and uses the compute_nao.py python script to compute the NAO index. #!/usr/bin/env python import cf import sys import glob from origin import * def get_NAO_djf(field): ''' Compute a DJF NAO index by box averaging Azores (20:28W,36:40N) - Iceland (16:25W,63:70N) and averaging over Dec-Jan-Feb ''' #assume field== MSLP! #get sub-regions for boxes iceland_box=field.subspace(X=cf.wi(-25,-16),Y=cf.wi(63,70)) azores_box=field.subspace(X=cf.wi(-28,-20),Y=cf.wi(36,40)) #compute the area means (weighted by cell area) and difference nao=azores_box.collapse('area: mean',weights=True,squeeze=True)-iceland_box.collapse('area: mean', weights=True,squeeze=True) #compute the DJF mean nao_mean=nao.collapse('time: mean',group=cf.djf()) #change the name nao_mean.standard_name='NAO_djf' #And the netcdf name nao_mean.nc_set_variable('NAO_djf') #and the long_name nao_mean.set_properties({'long_name':'NAO_djf'}) #return nao index return(nao_mean) #Atmosphere grid cell area areacella='/home/users/dlrhodso/CANARI/SPRINT_2024/analysis/areacella_fx_HadGEM3-GC31-MM_piControl_r1i1p1f1_gn_fixed.nc' #a tag definining what this index is outfile_origin=\"DJF NAO index computed as the Azores (20:28W, 36:40N) box mean minus Iceland (16:25W,63:70N) box mean \" #First argument is scratch directory scratch=sys.argv[1] #file pattern for the MSLP diagnostic (m01s16i222) #Only daily mean MSLP is available file=sys.argv[2]+'/ATM/yearly/*/*day_m01s16i222*' #expand this pattern files=glob.glob(file) #create output filename outfilename=scratch+'/nao-djf_'+files[0].split('/')[-1] #read in data, adding in the cell area from the external file data=cf.read(file,external=areacella) #compute nao index nao_djf=get_NAO_djf(data[0]) #write out NAO index with description text o_write(nao_djf,outfilename,outfile_origin) print(\"Written \"+outfilename) This script will write the output to scratch_pw3/NAO/ as files for each ensemble member Computing a box average index for SST compute_SPG_T.sh #!/usr/bin/env python import cf import sys import glob from origin import * def compute_spg(field): ''' compute SPG 50:65N 0:60W ''' #compute SPG over 50:65N, 0:60W and 1st ocean layer (0:1m) #extract subspace sub_field=field.subspace(latitude=cf.wi(50,65),longitude=cf.wi(-60,0)).squeeze() #compute mean over subspace, weighting by area spg=sub_field.collapse('area: mean', weights='area',squeeze=True) #add names spg.standard_name='sub_polar_gyre_index_50_65N' spg.nc_set_variable('SPG_50_65N') spg.set_properties({'long_name':'sub_polar_gyre_50_60N'}) return(spg) #ocean cell area file areacello=\"areacello.nc\" #a tag definining what this index is outfile_origin=\"SubPolar Gyre Temperaure index computed as the box mean of over () box mean \" #First argument is scratch directory scratch=sys.argv[1] #file pattern for the SST diagnostic #file to read in file=sys.argv[2] #file name to write out outfilename=sys.argv[3] #variable name variable=sys.argv[4] #expand this pattern year,fname=file.split('/')[-2:] #read in data, adding in the cell area from the external file data=cf.read(file,external=areacello) if len(data)>1: print(\"Aggregation failed!\") exit() #axis labels need to be added data[0].coord('long_name=cell index along first dimension').axis='X' data[0].coord('long_name=cell index along second dimension').axis='Y' #compute spg index varname=\"SPG_\"+variable index=compute_spg(data[0]) index.standard_name=varname index.nc_set_variable(varname) #compute the monthly means index_monthly=index.collapse('time: mean', group=cf.M()) index_monthly.standard_name=varname+\"_mon\" index_monthly.nc_set_variable(varname+\"_mon\") #compute the annual means index_annual=index.collapse('time: mean', group=cf.Y()) index_annual.standard_name=varname+\"_ann\" index_annual.nc_set_variable(varname+\"_ann\") outlist=cf.FieldList() outlist.append(index) outlist.append(index_monthly) outlist.append(index_annual) #write out NAO index with description text o_write(outlist,outfilename,outfile_origin) print(\"Written \"+outfilename) This produces multiple files in scratch_pw3 that need to be assembled into a single file for each ensemble member. concat_SPG_T.sh does this usings concat_cf.py .","title":"Computing indices with cf-python"},{"location":"cf_python/#computing-indices-with-cf-python","text":"cf-python is a python Earth Science data analysis library that is built on a complete implementation of the CF data model. It makes reading, writing and processing of cf netcdf data very simple. This tutorial points to some basic examples for use on the CANARI SPRINT data on JASMIN These examples can all be found in /home/users/dlrhodso/CANARI/SPRINT_2024/examples . All sumbit submit multiple jobs in parallel in order to process all ensemble members at once. They use the LOTUS script to do this - this is a wrapper script for the SLURM submission commands that make it very easy to submit jobs and not worry about log files etc. All these scripts use the default JASMIN sci JASPY enviromnet ( module load jaspy ) - but the LOTUS script automatically loads JASPY.","title":"Computing indices with cf-python"},{"location":"cf_python/#computing-a-box-average-nao-index","text":"compute_nao.sh loops over all MSLP files in the /gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2 directory and uses the compute_nao.py python script to compute the NAO index. #!/usr/bin/env python import cf import sys import glob from origin import * def get_NAO_djf(field): ''' Compute a DJF NAO index by box averaging Azores (20:28W,36:40N) - Iceland (16:25W,63:70N) and averaging over Dec-Jan-Feb ''' #assume field== MSLP! #get sub-regions for boxes iceland_box=field.subspace(X=cf.wi(-25,-16),Y=cf.wi(63,70)) azores_box=field.subspace(X=cf.wi(-28,-20),Y=cf.wi(36,40)) #compute the area means (weighted by cell area) and difference nao=azores_box.collapse('area: mean',weights=True,squeeze=True)-iceland_box.collapse('area: mean', weights=True,squeeze=True) #compute the DJF mean nao_mean=nao.collapse('time: mean',group=cf.djf()) #change the name nao_mean.standard_name='NAO_djf' #And the netcdf name nao_mean.nc_set_variable('NAO_djf') #and the long_name nao_mean.set_properties({'long_name':'NAO_djf'}) #return nao index return(nao_mean) #Atmosphere grid cell area areacella='/home/users/dlrhodso/CANARI/SPRINT_2024/analysis/areacella_fx_HadGEM3-GC31-MM_piControl_r1i1p1f1_gn_fixed.nc' #a tag definining what this index is outfile_origin=\"DJF NAO index computed as the Azores (20:28W, 36:40N) box mean minus Iceland (16:25W,63:70N) box mean \" #First argument is scratch directory scratch=sys.argv[1] #file pattern for the MSLP diagnostic (m01s16i222) #Only daily mean MSLP is available file=sys.argv[2]+'/ATM/yearly/*/*day_m01s16i222*' #expand this pattern files=glob.glob(file) #create output filename outfilename=scratch+'/nao-djf_'+files[0].split('/')[-1] #read in data, adding in the cell area from the external file data=cf.read(file,external=areacella) #compute nao index nao_djf=get_NAO_djf(data[0]) #write out NAO index with description text o_write(nao_djf,outfilename,outfile_origin) print(\"Written \"+outfilename) This script will write the output to scratch_pw3/NAO/ as files for each ensemble member","title":"Computing a box average NAO index"},{"location":"cf_python/#computing-a-box-average-index-for-sst","text":"compute_SPG_T.sh #!/usr/bin/env python import cf import sys import glob from origin import * def compute_spg(field): ''' compute SPG 50:65N 0:60W ''' #compute SPG over 50:65N, 0:60W and 1st ocean layer (0:1m) #extract subspace sub_field=field.subspace(latitude=cf.wi(50,65),longitude=cf.wi(-60,0)).squeeze() #compute mean over subspace, weighting by area spg=sub_field.collapse('area: mean', weights='area',squeeze=True) #add names spg.standard_name='sub_polar_gyre_index_50_65N' spg.nc_set_variable('SPG_50_65N') spg.set_properties({'long_name':'sub_polar_gyre_50_60N'}) return(spg) #ocean cell area file areacello=\"areacello.nc\" #a tag definining what this index is outfile_origin=\"SubPolar Gyre Temperaure index computed as the box mean of over () box mean \" #First argument is scratch directory scratch=sys.argv[1] #file pattern for the SST diagnostic #file to read in file=sys.argv[2] #file name to write out outfilename=sys.argv[3] #variable name variable=sys.argv[4] #expand this pattern year,fname=file.split('/')[-2:] #read in data, adding in the cell area from the external file data=cf.read(file,external=areacello) if len(data)>1: print(\"Aggregation failed!\") exit() #axis labels need to be added data[0].coord('long_name=cell index along first dimension').axis='X' data[0].coord('long_name=cell index along second dimension').axis='Y' #compute spg index varname=\"SPG_\"+variable index=compute_spg(data[0]) index.standard_name=varname index.nc_set_variable(varname) #compute the monthly means index_monthly=index.collapse('time: mean', group=cf.M()) index_monthly.standard_name=varname+\"_mon\" index_monthly.nc_set_variable(varname+\"_mon\") #compute the annual means index_annual=index.collapse('time: mean', group=cf.Y()) index_annual.standard_name=varname+\"_ann\" index_annual.nc_set_variable(varname+\"_ann\") outlist=cf.FieldList() outlist.append(index) outlist.append(index_monthly) outlist.append(index_annual) #write out NAO index with description text o_write(outlist,outfilename,outfile_origin) print(\"Written \"+outfilename) This produces multiple files in scratch_pw3 that need to be assembled into a single file for each ensemble member. concat_SPG_T.sh does this usings concat_cf.py .","title":"Computing a box average index for SST"},{"location":"creating_your_own_conda_env/","text":"Tutorial 3 - Creating and sharing your own conda/mamba environment Why create your own environment? The provided environment (located in /gws/smf/j04/canari/conda-env) contains many packages you are likely to need, but doesn't contain everything. As this is a shared environment we can't allow everyone to install new packages into it. If you need extra packages you will have to create your own environment. Creating an environment from the JASMIN Jupyter Notebook Service It is assumed you have cloned the tutorials Github repository into a directory called tutorials, if you haven't see the \"Getting the CANARI example code\" section of tutorial 2 (Configuring and Using the JASMIN Notebooks Service). In a terminal on the notebook service (note: this will not work on a Sci server) run the command mamba env create -n canari -f ~/tutorials/environment.yml . We are using the command mamba instead of conda . Mamba is a replacement for conda that can resolve the dependencies for an enviroment much faster. This will take about 10 minutes to execute. After it is complete, verify it exists by running: mamba env list , you should see something similar to the following: # conda environments: # /gws/smf/j04/canari/conda-env canari /home/users/colinsau/.conda/envs/canari To make the enviroment visible to Jupyter Lab run (\"CANARI-mine\" is the name it will show in the Jupyter Launcher, feel free to change this): mamba run -n canari python -m ipykernel install --user --name CANARI-mine . After about one minute a new icon called \"CANARI-mine\" should apear in the Jupyter launcher. Adding extra packages to your environment Installing extra packages with Mamba We can install extra packages in our mamba/conda enviroment by using the mamba install command from a terminal inside the JASMIN notebook service. We need to specify the name of our enviroment with the -n option. If for example we wanted to install plotnine (which creates R ggplot2 style plots in Python) then we could install it by typing: mamba install -n canari plotnine Installing extra packages with Pip Sometimes packages aren't available via Mamba/Conda but are available via Python's pip package manager. Always try to install via Mamba in the first instance though. To install plotnine using pip run the command: mamba run -n canari pip install plotnine If you already installed plotnine using mamba then this will detect the installation and refuse to install it again. Sharing your enviroment Now you've added more packages to your enviroment you might want to share your enviroment with somebody else (or yourself on a different computer). Mamba/Conda allows us to export a list of all packages installed in an enviroment with the mamba env export command. An example use of this command is: mamba env export -n canari --from-history -f new_environment.yml As with other Mamba commands this takes a -n parameter for the name of the enviroment we're exporting. The option --from-history this means that the export will reflect the package versions we specified, for example we might have requested Python version 3.10.12 instead of the exact version we got which might have been something like version 3.10.2=hd12c33a_0_cpython. These overly precise version numbers can cause problems when trying to replicate the enviroment on another computer, especially if it runs a different operating system. We can specify an output file with the -f parameter, if this isn't specified then the environment data is displayed on screen. The resulting file (new_enviroment.yml) can now be shared with somebody else or added to a git repository. To install a new enviroment using this file run the command mamba env create -n canari-new -f new_enviroment.yml . This will create a new enviorment called \"canari-new\" from the file new_enviroment.yml that we just exported.","title":"Creating your own conda env"},{"location":"creating_your_own_conda_env/#tutorial-3-creating-and-sharing-your-own-condamamba-environment","text":"","title":"Tutorial 3 - Creating and sharing your own conda/mamba environment"},{"location":"creating_your_own_conda_env/#why-create-your-own-environment","text":"The provided environment (located in /gws/smf/j04/canari/conda-env) contains many packages you are likely to need, but doesn't contain everything. As this is a shared environment we can't allow everyone to install new packages into it. If you need extra packages you will have to create your own environment.","title":"Why create your own environment?"},{"location":"creating_your_own_conda_env/#creating-an-environment-from-the-jasmin-jupyter-notebook-service","text":"It is assumed you have cloned the tutorials Github repository into a directory called tutorials, if you haven't see the \"Getting the CANARI example code\" section of tutorial 2 (Configuring and Using the JASMIN Notebooks Service). In a terminal on the notebook service (note: this will not work on a Sci server) run the command mamba env create -n canari -f ~/tutorials/environment.yml . We are using the command mamba instead of conda . Mamba is a replacement for conda that can resolve the dependencies for an enviroment much faster. This will take about 10 minutes to execute. After it is complete, verify it exists by running: mamba env list , you should see something similar to the following: # conda environments: # /gws/smf/j04/canari/conda-env canari /home/users/colinsau/.conda/envs/canari To make the enviroment visible to Jupyter Lab run (\"CANARI-mine\" is the name it will show in the Jupyter Launcher, feel free to change this): mamba run -n canari python -m ipykernel install --user --name CANARI-mine . After about one minute a new icon called \"CANARI-mine\" should apear in the Jupyter launcher.","title":"Creating an environment from the JASMIN Jupyter Notebook Service"},{"location":"creating_your_own_conda_env/#adding-extra-packages-to-your-environment","text":"","title":"Adding extra packages to your environment"},{"location":"creating_your_own_conda_env/#installing-extra-packages-with-mamba","text":"We can install extra packages in our mamba/conda enviroment by using the mamba install command from a terminal inside the JASMIN notebook service. We need to specify the name of our enviroment with the -n option. If for example we wanted to install plotnine (which creates R ggplot2 style plots in Python) then we could install it by typing: mamba install -n canari plotnine","title":"Installing extra packages with Mamba"},{"location":"creating_your_own_conda_env/#installing-extra-packages-with-pip","text":"Sometimes packages aren't available via Mamba/Conda but are available via Python's pip package manager. Always try to install via Mamba in the first instance though. To install plotnine using pip run the command: mamba run -n canari pip install plotnine If you already installed plotnine using mamba then this will detect the installation and refuse to install it again.","title":"Installing extra packages with Pip"},{"location":"creating_your_own_conda_env/#sharing-your-enviroment","text":"Now you've added more packages to your enviroment you might want to share your enviroment with somebody else (or yourself on a different computer). Mamba/Conda allows us to export a list of all packages installed in an enviroment with the mamba env export command. An example use of this command is: mamba env export -n canari --from-history -f new_environment.yml As with other Mamba commands this takes a -n parameter for the name of the enviroment we're exporting. The option --from-history this means that the export will reflect the package versions we specified, for example we might have requested Python version 3.10.12 instead of the exact version we got which might have been something like version 3.10.2=hd12c33a_0_cpython. These overly precise version numbers can cause problems when trying to replicate the enviroment on another computer, especially if it runs a different operating system. We can specify an output file with the -f parameter, if this isn't specified then the environment data is displayed on screen. The resulting file (new_enviroment.yml) can now be shared with somebody else or added to a git repository. To install a new enviroment using this file run the command mamba env create -n canari-new -f new_enviroment.yml . This will create a new enviorment called \"canari-new\" from the file new_enviroment.yml that we just exported.","title":"Sharing your enviroment"},{"location":"data/","text":"Data The CANARI-LE has now completed running on is currently being run on ARCHER2 with data being stored on tape on JASMIN with some data being stored in the CANARI group workspace (gws). Ensemble Details Model: HadGEM3-GC1.3-MM, same configuration as used in CMIP6, global configuration version 3.1 Ocean: NEMO3.6 Atmosphere: UM Sea Ice: CICE Land: Jules 40 historical (1950-2014) ensemble members 40 future projection, SSP3-7.0 (2015-2100) ensemble members More information on the CANARI-LE can be found here . State of Ensemble Currently running historical simulations, with 27 ensemble members completed and 13 running. Detailed information on the state of the ensemble can be found here . Data Access To access the CANARI-LE data available on JASMIN you need to apply for access to the CANARI gws through the JASMIN accounts portal under the my services button. An example set of data is currently uploaded onto the CANARI gws (/gws/nopw/j04/canari/users/reinhard/data/u-cy573-sample) and priority variables are in process of being downloaded from tape to JASMIN (/gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2). The list of priority variables are on this spreadsheet . You can find the long names for the variables and the short names used in the netcdf files. Please pay particular attention to the notes in red. Useful Files For the ocean the mesh_mask and subbasins files can be found in the CANARI gws here /gws/nopw/j04/canari/shared/large-ensemble/ocean How to cite There is no specific paper yet on the large ensemble, so please reference the HadGEM3.1 paper ( Williams et al. 2017 ) and acknowledge CANARI and JASMIN. HadGEM3-GC3.1-MM Papers Williams et al. 2017 The Met Office Global Coupled Model 3.0 and 3.1 (GC3.0 and GC3.1) Configurations Menary et al. 2018 Preindustrial Control Simulations With HadGEM3-GC3.1 for CMIP6 Andrews et al. 2020 Historical Simulations With HadGEM3-GC3.1 for CMIP6 Lai et al. 2022 Mechanisms of Internal Atlantic Multidecadal Variability in HadGEM3-GC3.1 at Two Different Resolutions","title":"Data"},{"location":"data/#data","text":"The CANARI-LE has now completed running on is currently being run on ARCHER2 with data being stored on tape on JASMIN with some data being stored in the CANARI group workspace (gws).","title":"Data"},{"location":"data/#ensemble-details","text":"Model: HadGEM3-GC1.3-MM, same configuration as used in CMIP6, global configuration version 3.1 Ocean: NEMO3.6 Atmosphere: UM Sea Ice: CICE Land: Jules 40 historical (1950-2014) ensemble members 40 future projection, SSP3-7.0 (2015-2100) ensemble members More information on the CANARI-LE can be found here .","title":"Ensemble Details"},{"location":"data/#state-of-ensemble","text":"Currently running historical simulations, with 27 ensemble members completed and 13 running. Detailed information on the state of the ensemble can be found here .","title":"State of Ensemble"},{"location":"data/#data-access","text":"To access the CANARI-LE data available on JASMIN you need to apply for access to the CANARI gws through the JASMIN accounts portal under the my services button. An example set of data is currently uploaded onto the CANARI gws (/gws/nopw/j04/canari/users/reinhard/data/u-cy573-sample) and priority variables are in process of being downloaded from tape to JASMIN (/gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2). The list of priority variables are on this spreadsheet . You can find the long names for the variables and the short names used in the netcdf files. Please pay particular attention to the notes in red.","title":"Data Access"},{"location":"data/#useful-files","text":"For the ocean the mesh_mask and subbasins files can be found in the CANARI gws here /gws/nopw/j04/canari/shared/large-ensemble/ocean","title":"Useful Files"},{"location":"data/#how-to-cite","text":"There is no specific paper yet on the large ensemble, so please reference the HadGEM3.1 paper ( Williams et al. 2017 ) and acknowledge CANARI and JASMIN.","title":"How to cite"},{"location":"data/#hadgem3-gc31-mm-papers","text":"Williams et al. 2017 The Met Office Global Coupled Model 3.0 and 3.1 (GC3.0 and GC3.1) Configurations Menary et al. 2018 Preindustrial Control Simulations With HadGEM3-GC3.1 for CMIP6 Andrews et al. 2020 Historical Simulations With HadGEM3-GC3.1 for CMIP6 Lai et al. 2022 Mechanisms of Internal Atlantic Multidecadal Variability in HadGEM3-GC3.1 at Two Different Resolutions","title":"HadGEM3-GC3.1-MM Papers"},{"location":"github/","text":"Git Setup and Basics About Git and GitHub Git is a popular version control system that is the foundation of most open source software development. You are not required to be a Git pro in advance of this event, but come prepared to learn a lot about it! GitHub is a hosting service for Git repositories, enabling us to share code across teams in a web environment. We will use Git and GitHub for collaborative work. Git Installation Windows Install Git for Windows from this link . For more setup details follow these instructions Mac OS Download the git installer and run it. Linux (Debian/Ubuntu): sudo apt install git-all To test, open the terminal (on Windows, Git Bash) and setup your username and email: git config --global user.name \"your username\" git config --global user.email \"your email\" Getting started with Bash terminal During the CANARI-Sprint week it will be useful to know how to navigate between files from the command line. If you are not familiar with the linux shell commands, you can review the first three sections of this Software Carpentry Shell Novice lesson. On Windows, use the Git Bash terminal to run these commands. Terminal (command line) text editor When working on the command line (the terminal or shell), it is often handy to modify file content directly from there. For that you can use a command line editor such as nano . On Mac and Linux it is usually pre-installed, and on Windows it is installed when you install Git (see here for more information about nano and its configuration). Test your installation by opening a terminal and running nano --version . If it works you can link your git configuration with nano : git config --global core.editor \"nano -w\" Git steps and workflows 1. Create a project repository On your own or someone in your project group (preferably one who has done it before), create a repository for the project under the CANARI-sprint organization, https://github.com/CANARI-sprint Click New and follow the steps: check yes to create a README.md file. Format project name as proj-myprojectname (you can change the name later), where myprojectname is a brief name for your project Invite others to the repo: Settings -> Collaborators Note to collaborators: you will receive an invitation to your email associated with github.com. If you cannnot find it look for the bell notifications on the top right of the website. 2. Clone the repository Each participant should clone the repository so they have their copy on their JupyterHub account space (and locally in the participant's computer, if desired). Navigate through the terminal to the folder where you want to keep CANARI-Sprint work ( cd path_to_canari-sprint-work ). git clone https://github.com/CANARI-Sprint/proj-myprojectname.git This will create a new folder called proj-myprojectname . Navigate ( cd ) to this new folder. 3. Update the README with your name Open the README.md file with your favorite editor and create a new section header. Under this section add your name. Then add this change, commit it to the local repository, and push it so that it appears on the origin GitHub repository. git add README.md git commit -m \"Adding new name to README.md\" git push origin Make sure your change appears online. Remember to run git status to observe the changes made into your repository. Pay attention to the colors. To see the changes in the files run git diff . 4. Update your local repository (local clone) with the changes of your collaborators git pull origin main Short names for repositories: : Remember origin is just a short name of the web address of the repository. To see what is hidden in origin: git remote -v To continue practicing these steps, make more changes to the title and the description of the project. Ran into a problem? !ATTENTION When working with several people sometimes you Cannot push because changes have been made that have not been incorporated: need to first pull When pulling you arrive into a merge conflict: need to resolve the conflict manually #### 5. Resolving the merge conflict ```bash git status You will see the file(s) which caused the merge conflict in green. Open it and detect the conflict by the special format: <<<<<<< HEAD my text ======= somebody else's text >>>>>>> 35ab35436 Decide which changes you want to keep, and modify the file so it looks as you wish directly from the editor. Remove the unnecessary characters. Add, commit and push the changes. git add README.md git commit -m \"resolving merge conflict\" git push origin main You can continue working on as usual. Remember to pull often and push small changes ... to avoid messing with complicated merges and keep your repo up-to-date. Troubleshooting Deleting files git rm filename.txt rm filename.txt Note : git rm just removes the file from git, to delete the file completely use the bash rm command after that. Reverting to the previous commit git revert HEAD Note : Your files in the local repo will still be there. References and Resources Git and GitHub are very powerful tools but no doubt the learning curve is steep. Learning is an iterative process so below we list some resources which can help you be better prepared: git-novice - Software Carpentry Lesson (3 hours with exercises) Setting Up Git - Software Carpentry Lesson Atlassian Tutorials - Version Control An excellent guide to the Forking Git Workflow: Step-by-step guide to contributing on GitHub What is GitHub? (3:45 min) GitHub Learning Lab : practice with a bot! (On your own pace) An interactive Git Tutorial: the tool you didn\u2019t know you needed. From personal workflows to open collaboration GeoHackWeek 2019 tutorial: Getting started with Git ICESAT-2HackWeek intro-jupyter-git repo , with several notebooks going into a lot of detail.","title":"Github"},{"location":"github/#git-setup-and-basics","text":"","title":"Git Setup and Basics"},{"location":"github/#about-git-and-github","text":"Git is a popular version control system that is the foundation of most open source software development. You are not required to be a Git pro in advance of this event, but come prepared to learn a lot about it! GitHub is a hosting service for Git repositories, enabling us to share code across teams in a web environment. We will use Git and GitHub for collaborative work.","title":"About Git and GitHub"},{"location":"github/#git-installation","text":"Windows Install Git for Windows from this link . For more setup details follow these instructions Mac OS Download the git installer and run it. Linux (Debian/Ubuntu): sudo apt install git-all To test, open the terminal (on Windows, Git Bash) and setup your username and email: git config --global user.name \"your username\" git config --global user.email \"your email\"","title":"Git Installation"},{"location":"github/#getting-started-with-bash-terminal","text":"During the CANARI-Sprint week it will be useful to know how to navigate between files from the command line. If you are not familiar with the linux shell commands, you can review the first three sections of this Software Carpentry Shell Novice lesson. On Windows, use the Git Bash terminal to run these commands.","title":"Getting started with Bash terminal"},{"location":"github/#terminal-command-line-text-editor","text":"When working on the command line (the terminal or shell), it is often handy to modify file content directly from there. For that you can use a command line editor such as nano . On Mac and Linux it is usually pre-installed, and on Windows it is installed when you install Git (see here for more information about nano and its configuration). Test your installation by opening a terminal and running nano --version . If it works you can link your git configuration with nano : git config --global core.editor \"nano -w\"","title":"Terminal (command line) text editor"},{"location":"github/#git-steps-and-workflows","text":"","title":"Git steps and workflows"},{"location":"github/#1-create-a-project-repository","text":"On your own or someone in your project group (preferably one who has done it before), create a repository for the project under the CANARI-sprint organization, https://github.com/CANARI-sprint Click New and follow the steps: check yes to create a README.md file. Format project name as proj-myprojectname (you can change the name later), where myprojectname is a brief name for your project Invite others to the repo: Settings -> Collaborators Note to collaborators: you will receive an invitation to your email associated with github.com. If you cannnot find it look for the bell notifications on the top right of the website.","title":"1. Create a project repository"},{"location":"github/#2-clone-the-repository","text":"Each participant should clone the repository so they have their copy on their JupyterHub account space (and locally in the participant's computer, if desired). Navigate through the terminal to the folder where you want to keep CANARI-Sprint work ( cd path_to_canari-sprint-work ). git clone https://github.com/CANARI-Sprint/proj-myprojectname.git This will create a new folder called proj-myprojectname . Navigate ( cd ) to this new folder.","title":"2. Clone the repository"},{"location":"github/#3-update-the-readme-with-your-name","text":"Open the README.md file with your favorite editor and create a new section header. Under this section add your name. Then add this change, commit it to the local repository, and push it so that it appears on the origin GitHub repository. git add README.md git commit -m \"Adding new name to README.md\" git push origin Make sure your change appears online. Remember to run git status to observe the changes made into your repository. Pay attention to the colors. To see the changes in the files run git diff .","title":"3. Update the README with your name"},{"location":"github/#4-update-your-local-repository-local-clone-with-the-changes-of-your-collaborators","text":"git pull origin main Short names for repositories: : Remember origin is just a short name of the web address of the repository. To see what is hidden in origin: git remote -v To continue practicing these steps, make more changes to the title and the description of the project. Ran into a problem? !ATTENTION When working with several people sometimes you Cannot push because changes have been made that have not been incorporated: need to first pull When pulling you arrive into a merge conflict: need to resolve the conflict manually #### 5. Resolving the merge conflict ```bash git status You will see the file(s) which caused the merge conflict in green. Open it and detect the conflict by the special format: <<<<<<< HEAD my text ======= somebody else's text >>>>>>> 35ab35436 Decide which changes you want to keep, and modify the file so it looks as you wish directly from the editor. Remove the unnecessary characters. Add, commit and push the changes. git add README.md git commit -m \"resolving merge conflict\" git push origin main You can continue working on as usual. Remember to pull often and push small changes ... to avoid messing with complicated merges and keep your repo up-to-date.","title":"4. Update your local repository (local clone) with the changes of your collaborators"},{"location":"github/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"github/#deleting-files","text":"git rm filename.txt rm filename.txt Note : git rm just removes the file from git, to delete the file completely use the bash rm command after that.","title":"Deleting files"},{"location":"github/#reverting-to-the-previous-commit","text":"git revert HEAD Note : Your files in the local repo will still be there.","title":"Reverting to the previous commit"},{"location":"github/#references-and-resources","text":"Git and GitHub are very powerful tools but no doubt the learning curve is steep. Learning is an iterative process so below we list some resources which can help you be better prepared: git-novice - Software Carpentry Lesson (3 hours with exercises) Setting Up Git - Software Carpentry Lesson Atlassian Tutorials - Version Control An excellent guide to the Forking Git Workflow: Step-by-step guide to contributing on GitHub What is GitHub? (3:45 min) GitHub Learning Lab : practice with a bot! (On your own pace) An interactive Git Tutorial: the tool you didn\u2019t know you needed. From personal workflows to open collaboration GeoHackWeek 2019 tutorial: Getting started with Git ICESAT-2HackWeek intro-jupyter-git repo , with several notebooks going into a lot of detail.","title":"References and Resources"},{"location":"highlights/","text":"Highlights January 2025 Updates begin January 27, 2025! March 2024 Day 5 Motivated by Bablu's time series of heat fluxes over the sub polar gyre (SPG), Simon has been looking at the difference in air-sea heat from between the post-2000 period and 1970-89. The key features are the weakening of heat loss (red colors) in the SPG which is potentially linked to the weakening of the AMOC found by Adam and Niamh. Process chain would be : weaker AMOC beings less warm water northwards, reduces SST and thus surface heat loss. And secondly the increase in heat loss in the Arctic (blue) which is presumably related to sea ice decline exposing more of the ocean surface and thus enabling greater heat loss to the atmosphere. Day 4 Amulya showed results which investigated the response of precipitation to changes in the jet at the end of day highlights meeting. Here is a figure of the relationship between the JJA jet latitude (left) and the DJF jet speed and precipitation over the UK. Wilson has been looking at precipitation of the UK, which he nicely showed at the end of day highlights meeting. Here is his time series of the Standardised Precipitation Index (SPI) accumulated over 3 months (SPI-3)UK average compared with SPI calculated from observations (HadUK-Grid). Paul has been busy looking at precipitation in the CANARI-LE and putting it into perspective with other LE. The figures below show the MJJAS (NDJFM) precipitation for the Northern (Southern) hemisphere (see the #sprint-highlights Slack channel for more figures). Laura has been looking at the relationship between the winter (DJF) NAO/EAP and 2 m temperature and precipitation. The figure below shows the results for 2 m temperature (see the #sprint-highlights Slack channel for more figures). Day 3 First results from Claire investigating sea surface temperature in cold air outbreak regions. More AMOC plots from Niamh, this time in depth space at 40N. Here are some Adam's plots of annual mean AMOC index at 26N and 1 km depth. Now available, thanks to Adam, AMOC in depth and density space (/gws/nopw/j04/canari/shared/large-ensemble/derived/HIST2/ ensemble num /OCN/yearly/ year /). First results from Lizzie, composite of DJF sea level pressure for strong - weak polar vortex. Day 2 First results from Bablu, the surface ocean heat flux in the sub-polar gyre for all ensemble members. First results from Tony who is looking sudden stratospheric warming, the figure takes a look at the annual cycle of 10hPa U in ensemble member 1. Years with suspected SSW are highlighted in colour, others are in grey. Day 1 First results from Dan, the mean sub-polar gyre (50:65N, 0:60W) SST and upper 500 m potential temperature. With shading showing +/- 1 standard deviation. The sprint has begun!","title":"Highlights"},{"location":"highlights/#highlights","text":"","title":"Highlights"},{"location":"highlights/#january-2025","text":"Updates begin January 27, 2025!","title":"January 2025"},{"location":"highlights/#march-2024","text":"Day 5 Motivated by Bablu's time series of heat fluxes over the sub polar gyre (SPG), Simon has been looking at the difference in air-sea heat from between the post-2000 period and 1970-89. The key features are the weakening of heat loss (red colors) in the SPG which is potentially linked to the weakening of the AMOC found by Adam and Niamh. Process chain would be : weaker AMOC beings less warm water northwards, reduces SST and thus surface heat loss. And secondly the increase in heat loss in the Arctic (blue) which is presumably related to sea ice decline exposing more of the ocean surface and thus enabling greater heat loss to the atmosphere. Day 4 Amulya showed results which investigated the response of precipitation to changes in the jet at the end of day highlights meeting. Here is a figure of the relationship between the JJA jet latitude (left) and the DJF jet speed and precipitation over the UK. Wilson has been looking at precipitation of the UK, which he nicely showed at the end of day highlights meeting. Here is his time series of the Standardised Precipitation Index (SPI) accumulated over 3 months (SPI-3)UK average compared with SPI calculated from observations (HadUK-Grid). Paul has been busy looking at precipitation in the CANARI-LE and putting it into perspective with other LE. The figures below show the MJJAS (NDJFM) precipitation for the Northern (Southern) hemisphere (see the #sprint-highlights Slack channel for more figures). Laura has been looking at the relationship between the winter (DJF) NAO/EAP and 2 m temperature and precipitation. The figure below shows the results for 2 m temperature (see the #sprint-highlights Slack channel for more figures). Day 3 First results from Claire investigating sea surface temperature in cold air outbreak regions. More AMOC plots from Niamh, this time in depth space at 40N. Here are some Adam's plots of annual mean AMOC index at 26N and 1 km depth. Now available, thanks to Adam, AMOC in depth and density space (/gws/nopw/j04/canari/shared/large-ensemble/derived/HIST2/ ensemble num /OCN/yearly/ year /). First results from Lizzie, composite of DJF sea level pressure for strong - weak polar vortex. Day 2 First results from Bablu, the surface ocean heat flux in the sub-polar gyre for all ensemble members. First results from Tony who is looking sudden stratospheric warming, the figure takes a look at the annual cycle of 10hPa U in ensemble member 1. Years with suspected SSW are highlighted in colour, others are in grey. Day 1 First results from Dan, the mean sub-polar gyre (50:65N, 0:60W) SST and upper 500 m potential temperature. With shading showing +/- 1 standard deviation. The sprint has begun!","title":"March 2024"},{"location":"jasmin_notebook_service/","text":"Configuring and Using the JASMIN Notebooks Service Logging into the JASMIN Notebook Service In your web browser visit https://notebooks.jasmin.ac.uk Login using your JASMIN username and password You will then be emailed a one time code, paste this into the verification code box. A Jupyter notebook interface will now be started and you can create a new notebook or open a terminal. Your JASMIN home directory and group workspaces will be accessible from within the notebook environment. Setting up the CANARI Conda Environment We have preconfigured a CANARI conda environment for you to use. This contains many (but perhaps not all) of the packages you are likely to need. It is built using the environment.yml file that can be found in the CANARI tutorials github . The environment is located on the Group Work Space under the path /gws/smf/j04/canari/conda-env , because it is held in a non-standard location your Jupyter notebooks won't find it automatically. In order to use it do the following: From the Jupyter launcher click on the terminal icon Type: conda run -p /gws/smf/j04/canari/conda-env python -m ipykernel install --user --name CANARI and press enter Open a new Jupyter launcher by clicking on File and then New Launcher There should now be a notebook and console option called CANARI, although this can take around one minute to appear. Getting the CANARI example code First ensure you are in your home directory by clicking on the folder icon in the file browser on the left side of the screen. Click on the Git menu and choose \"Clone a repo\" Enter https://github.com/CANARI-sprint/tutorials as the URI of the remote Git repository. Click Clone This will create a copy of the repository from https://github.com/CANARI-sprint/tutorials into your JASMIN home directory. Open and run an example notebook Click on the tutorials folder that contains your clone of the github repository. Open the notebooks folder. Choose the 1_basic_manipulation.ipynb notebook If you are asked which kernel you would like to use choose the CANARI kernel. Test the notebook can run by clicking on the Run menu and choosing \"Run all cells\" or going through each cell one by one and clicking the play button.","title":"Jasmin notebook service"},{"location":"jasmin_notebook_service/#configuring-and-using-the-jasmin-notebooks-service","text":"","title":"Configuring and Using the JASMIN Notebooks Service"},{"location":"jasmin_notebook_service/#logging-into-the-jasmin-notebook-service","text":"In your web browser visit https://notebooks.jasmin.ac.uk Login using your JASMIN username and password You will then be emailed a one time code, paste this into the verification code box. A Jupyter notebook interface will now be started and you can create a new notebook or open a terminal. Your JASMIN home directory and group workspaces will be accessible from within the notebook environment.","title":"Logging into the JASMIN Notebook Service"},{"location":"jasmin_notebook_service/#setting-up-the-canari-conda-environment","text":"We have preconfigured a CANARI conda environment for you to use. This contains many (but perhaps not all) of the packages you are likely to need. It is built using the environment.yml file that can be found in the CANARI tutorials github . The environment is located on the Group Work Space under the path /gws/smf/j04/canari/conda-env , because it is held in a non-standard location your Jupyter notebooks won't find it automatically. In order to use it do the following: From the Jupyter launcher click on the terminal icon Type: conda run -p /gws/smf/j04/canari/conda-env python -m ipykernel install --user --name CANARI and press enter Open a new Jupyter launcher by clicking on File and then New Launcher There should now be a notebook and console option called CANARI, although this can take around one minute to appear.","title":"Setting up the CANARI Conda Environment"},{"location":"jasmin_notebook_service/#getting-the-canari-example-code","text":"First ensure you are in your home directory by clicking on the folder icon in the file browser on the left side of the screen. Click on the Git menu and choose \"Clone a repo\" Enter https://github.com/CANARI-sprint/tutorials as the URI of the remote Git repository. Click Clone This will create a copy of the repository from https://github.com/CANARI-sprint/tutorials into your JASMIN home directory.","title":"Getting the CANARI example code"},{"location":"jasmin_notebook_service/#open-and-run-an-example-notebook","text":"Click on the tutorials folder that contains your clone of the github repository. Open the notebooks folder. Choose the 1_basic_manipulation.ipynb notebook If you are asked which kernel you would like to use choose the CANARI kernel. Test the notebook can run by clicking on the Run menu and choosing \"Run all cells\" or going through each cell one by one and clicking the play button.","title":"Open and run an example notebook"},{"location":"running_on_sci_servers/","text":"Running on the JASMIN Sci Servers The JASMIN notebook service only has limited resources and might not be sufficient for some larger datasets. One alternative is to use the Sci servers. These are 8 shared servers which JASMIN users can login to and run code on. Logging on to the Sci servers First login to the JASMIN login server (replace with your own username): ssh -A <jasminusername>@login1.jasmin.ac.uk Do not forget to add the -A option to add your SSH key to the session. Then login to one of the sci servers, there are 8 of these in total called sci1-8. ssh sci6 Or this can all be wrapped up in one command using an SSH \"jump host\" with: ssh -J <jasminusername>@login1.jasmin.ac.uk <jasminusername>@sci6 Anacionda, Miniconda or Micromamba? Unlike the Notebook server neither Conda or Mamba are installed by default on the Sci servers and we must install them ourselves. There are three possible options: Anaconda - A heavyweight distribution with many popular packages pre-installed. This is about 1 gigabyte in size. Miniconda - A lightweight dsitribution with only a few packages such as Python pre-installed. This is about 140 megabytes in size. Micromamba - The mamba package manager and nothing else, we can use this to install Python and any other packages we need. This is only 14 megabytes. All of these provide us with the conda or mamba package manager and let us download more packages if needed. Since it is the smallest and simplest, we'll use micromamba for this example. Feel free to follow the links above and use Anaconda or Miniconda if you prefer. Installing Micromamba To download Micromamba run the following: \"${SHELL}\" <(curl -L https://micro.mamba.pm/install.sh) This will then ask several questions about configuring Micromamba: When prompted for a micromaba binary folder choose the default choice of ~/.local/bin by pressing enter. Say yes to \"Init shell (bash)\" Say yes to \"Configure conda-forge\" For the Prefix Location put \"~/.conda\", this will store mamba environments in the same location as the notebook service was using. Micromamba will be compaitble with them. After micromamba has finished installing you will either need to logout and back in again or refresh your shell by typing source ~/.bashrc . At this point you should be able to run the micromamba command as a substitute for any of the mamba/conda commands we've used before. To test this run micromamba env list and you should get a list of all of your environments that you've used on the notebook service. Activating the shared CANARI environment If you want to run any code in the shared CANARI environment then you need to \"activate\" that enviroment (or use the micromamba run command). To do this run: micromamba activate -p /gws/smf/j04/canari/conda-env Your prompt should now change to start with (/gws/smf/j04/canari/conda-env) to indicate that this environment is now active. Running a JupyterLab instance on a Sci server It is recommended that you use your own copy of CANARI environment for this. If you haven't already made one see the instructions in tutorial 3 - Creating Your Own Conda Enviroment . Assuming you ran this tutorial you should have an environment called canari , go ahead and activate this by running: micromamba activate canari JupyterLab was already started and can be run with the command: jupyter-lab This will put a lot of text onto the screen, but at the bottom it will say something like: To access the server, open this file in a browser: file:///home/users/colinsau/.local/share/jupyter/runtime/jpserver-27367-open.html Or copy and paste one of these URLs: http://localhost:8889/lab?token=cb9017ebaf05fa72769e7136bbfed6373ddf12e5dd9213d7 http://127.0.0.1:8889/lab?token=cb9017ebaf05fa72769e7136bbfed6373ddf12e5dd9213d7 The JupyterLab is now running on the sci server you are logged into and listening to requests on port 8889 (your port number might be different, pay attention to this!). But to connect to it we need to open another SSH session. Note that you must leave this SSH session/terminal window open, if you press ctrl+c or close it then the JupyterLab session will stop. To open another SSH session open another terminal and run: ssh -J <jasminusername>@login1.jasmin.ac.uk -L 8889:localhost:8889 <jasminusername>@sci6 This will bring up a new terminal logged into sci6, but it will also forward requests on your own computer's port 8889 to sci6's port 8889 allowing you to access your Jupyter server on sci6. Now open a web browser and paste in one of the URLs starting \"http://\" from the output from starting JupyterLab. Shutting down your JupyterLab instance To shutdown your JupyterLab instance press the control key and c at the same time (ctrl+c) in the window where JupyterLab was running. It will ask you Shutdown this Jupyter server (y/[n])? press y and enter and then it will shutdown the JupyterLab instance.","title":"Running on sci servers"},{"location":"running_on_sci_servers/#running-on-the-jasmin-sci-servers","text":"The JASMIN notebook service only has limited resources and might not be sufficient for some larger datasets. One alternative is to use the Sci servers. These are 8 shared servers which JASMIN users can login to and run code on.","title":"Running on the JASMIN Sci Servers"},{"location":"running_on_sci_servers/#logging-on-to-the-sci-servers","text":"First login to the JASMIN login server (replace with your own username): ssh -A <jasminusername>@login1.jasmin.ac.uk Do not forget to add the -A option to add your SSH key to the session. Then login to one of the sci servers, there are 8 of these in total called sci1-8. ssh sci6 Or this can all be wrapped up in one command using an SSH \"jump host\" with: ssh -J <jasminusername>@login1.jasmin.ac.uk <jasminusername>@sci6","title":"Logging on to the Sci servers"},{"location":"running_on_sci_servers/#anacionda-miniconda-or-micromamba","text":"Unlike the Notebook server neither Conda or Mamba are installed by default on the Sci servers and we must install them ourselves. There are three possible options: Anaconda - A heavyweight distribution with many popular packages pre-installed. This is about 1 gigabyte in size. Miniconda - A lightweight dsitribution with only a few packages such as Python pre-installed. This is about 140 megabytes in size. Micromamba - The mamba package manager and nothing else, we can use this to install Python and any other packages we need. This is only 14 megabytes. All of these provide us with the conda or mamba package manager and let us download more packages if needed. Since it is the smallest and simplest, we'll use micromamba for this example. Feel free to follow the links above and use Anaconda or Miniconda if you prefer.","title":"Anacionda, Miniconda or Micromamba?"},{"location":"running_on_sci_servers/#installing-micromamba","text":"To download Micromamba run the following: \"${SHELL}\" <(curl -L https://micro.mamba.pm/install.sh) This will then ask several questions about configuring Micromamba: When prompted for a micromaba binary folder choose the default choice of ~/.local/bin by pressing enter. Say yes to \"Init shell (bash)\" Say yes to \"Configure conda-forge\" For the Prefix Location put \"~/.conda\", this will store mamba environments in the same location as the notebook service was using. Micromamba will be compaitble with them. After micromamba has finished installing you will either need to logout and back in again or refresh your shell by typing source ~/.bashrc . At this point you should be able to run the micromamba command as a substitute for any of the mamba/conda commands we've used before. To test this run micromamba env list and you should get a list of all of your environments that you've used on the notebook service.","title":"Installing Micromamba"},{"location":"running_on_sci_servers/#activating-the-shared-canari-environment","text":"If you want to run any code in the shared CANARI environment then you need to \"activate\" that enviroment (or use the micromamba run command). To do this run: micromamba activate -p /gws/smf/j04/canari/conda-env Your prompt should now change to start with (/gws/smf/j04/canari/conda-env) to indicate that this environment is now active.","title":"Activating the shared CANARI environment"},{"location":"running_on_sci_servers/#running-a-jupyterlab-instance-on-a-sci-server","text":"It is recommended that you use your own copy of CANARI environment for this. If you haven't already made one see the instructions in tutorial 3 - Creating Your Own Conda Enviroment . Assuming you ran this tutorial you should have an environment called canari , go ahead and activate this by running: micromamba activate canari JupyterLab was already started and can be run with the command: jupyter-lab This will put a lot of text onto the screen, but at the bottom it will say something like: To access the server, open this file in a browser: file:///home/users/colinsau/.local/share/jupyter/runtime/jpserver-27367-open.html Or copy and paste one of these URLs: http://localhost:8889/lab?token=cb9017ebaf05fa72769e7136bbfed6373ddf12e5dd9213d7 http://127.0.0.1:8889/lab?token=cb9017ebaf05fa72769e7136bbfed6373ddf12e5dd9213d7 The JupyterLab is now running on the sci server you are logged into and listening to requests on port 8889 (your port number might be different, pay attention to this!). But to connect to it we need to open another SSH session. Note that you must leave this SSH session/terminal window open, if you press ctrl+c or close it then the JupyterLab session will stop. To open another SSH session open another terminal and run: ssh -J <jasminusername>@login1.jasmin.ac.uk -L 8889:localhost:8889 <jasminusername>@sci6 This will bring up a new terminal logged into sci6, but it will also forward requests on your own computer's port 8889 to sci6's port 8889 allowing you to access your Jupyter server on sci6. Now open a web browser and paste in one of the URLs starting \"http://\" from the output from starting JupyterLab.","title":"Running a JupyterLab instance on a Sci server"},{"location":"running_on_sci_servers/#shutting-down-your-jupyterlab-instance","text":"To shutdown your JupyterLab instance press the control key and c at the same time (ctrl+c) in the window where JupyterLab was running. It will ask you Shutdown this Jupyter server (y/[n])? press y and enter and then it will shutdown the JupyterLab instance.","title":"Shutting down your JupyterLab instance"},{"location":"setup/","text":"Pre-event This page contains all the pre-event setup required to prepare you to make the most of the event. New items may appear on the list as the event gets closer. Sign-up for the event to make sure you are kept in the loop with the last information and see potential collaborators on the spreadsheet . Slack Workspace Make sure you can sign into the CANARI Slack workspace. If you don't have access to the CANARI slack space please contact Ben Harvey (b.j.harvey@ncas.ac.uk) or Jenny Mecking (jmecki@noc.ac.uk) to send you an invite. Join the appropriate channels on the CANARI Slack workspace, all channels relevant to the sprint will be prefaced with the word 'sprint'. There are channels setup where you can get help for the sprint which will be monitored, they will be labeled starting 'sprint-help'. Feel free to add channels to help collaborate your analysis during the sprint and make sure to label them with 'sprint'. JASMIN - keep in mind it might take a few days to get your accounts approved Make sure you have a JASMIN account. If you are new to JASMIN please mention the CANARI-LE sprint in your application. Instructions on signing up for an account can be found here . If you are only planning on using JASMIN for the sprint and don't have an account please contact Jenny Mecking (jmecki@noc.ac.uk) and a temporary account can be setup. Sign-up for the required JASMIN services through the accounts portal . Jasmin log-in account CANARI group workspace (gws) Please add your JASMIN user ID to the sign-up spreadsheet , ASAP, the list of user IDs will be shared with JASMIN. (optional) Link your JASMIN account with a CEDA account. This will provide you with access to several datasets including ERA5 and CMIP data. (optional) Set-up symbolic links to the CANARI gws to make it easier to find. (i.e. on JASMIN $ln -s /gws/nopw/j04/canari CANARI) ZOOM - communication during the sprint will be done via zoom, please make sure you are able to connect Plan your analysis Several work packages have been actively making plans on what they would like to do. If you are unsure of what analysis you are planning on doing in the first instance speak with your work package leader and/or centre lead (you can see who this is in the sign-up spread sheet). If that fails contact someone from the signup spreadsheet with similar interests to you. Take a look at the sample data on JASMIN to make sure the data you want to work with is there and looks correct. The sample data can be found here on JASMIN: /gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2 Shared datasets and shared analysis If you want to use any observation based dataset or other to compare the data from the CANARI-LE or already have dowloaded some datasets please fill in this spreadsheet . If you are planning on doing, would like to use or have already done some analysis that might be useful for multiple people (e.g. computing the Atlantic Multi-decadal Variability (AMV) or computing jet stream latitudes) please fill in this spreadsheet .","title":"Pre-event"},{"location":"setup/#pre-event","text":"This page contains all the pre-event setup required to prepare you to make the most of the event. New items may appear on the list as the event gets closer. Sign-up for the event to make sure you are kept in the loop with the last information and see potential collaborators on the spreadsheet . Slack Workspace Make sure you can sign into the CANARI Slack workspace. If you don't have access to the CANARI slack space please contact Ben Harvey (b.j.harvey@ncas.ac.uk) or Jenny Mecking (jmecki@noc.ac.uk) to send you an invite. Join the appropriate channels on the CANARI Slack workspace, all channels relevant to the sprint will be prefaced with the word 'sprint'. There are channels setup where you can get help for the sprint which will be monitored, they will be labeled starting 'sprint-help'. Feel free to add channels to help collaborate your analysis during the sprint and make sure to label them with 'sprint'. JASMIN - keep in mind it might take a few days to get your accounts approved Make sure you have a JASMIN account. If you are new to JASMIN please mention the CANARI-LE sprint in your application. Instructions on signing up for an account can be found here . If you are only planning on using JASMIN for the sprint and don't have an account please contact Jenny Mecking (jmecki@noc.ac.uk) and a temporary account can be setup. Sign-up for the required JASMIN services through the accounts portal . Jasmin log-in account CANARI group workspace (gws) Please add your JASMIN user ID to the sign-up spreadsheet , ASAP, the list of user IDs will be shared with JASMIN. (optional) Link your JASMIN account with a CEDA account. This will provide you with access to several datasets including ERA5 and CMIP data. (optional) Set-up symbolic links to the CANARI gws to make it easier to find. (i.e. on JASMIN $ln -s /gws/nopw/j04/canari CANARI) ZOOM - communication during the sprint will be done via zoom, please make sure you are able to connect Plan your analysis Several work packages have been actively making plans on what they would like to do. If you are unsure of what analysis you are planning on doing in the first instance speak with your work package leader and/or centre lead (you can see who this is in the sign-up spread sheet). If that fails contact someone from the signup spreadsheet with similar interests to you. Take a look at the sample data on JASMIN to make sure the data you want to work with is there and looks correct. The sample data can be found here on JASMIN: /gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2 Shared datasets and shared analysis If you want to use any observation based dataset or other to compare the data from the CANARI-LE or already have dowloaded some datasets please fill in this spreadsheet . If you are planning on doing, would like to use or have already done some analysis that might be useful for multiple people (e.g. computing the Atlantic Multi-decadal Variability (AMV) or computing jet stream latitudes) please fill in this spreadsheet .","title":"Pre-event"},{"location":"sprint/","text":"Sprint The sprint will take place March 4-8, 2024 as a hybrid sprint, with each participating centre working together and then connecting to each other via zoom. The goal of the sprint is to work together to kickstart analysis on the CANARI-LE data. Useful links participants list CANARI sprint GitHub Repositories list of useful datasets on JASMIN list of analysis useful to multiple people priority variables and variable names CANARI-LE information Schedule March 4, 2024: 9:45: Zoom channel opens for the day 10:00-10:10: Good morning and Welcome (Jenny Mecking) 10:10-10:20: Overview of CANARI (Len Shaffrey) 10:20-10:35: CANARI-LE overview (Reinhard Schiemann) 10:35-10:40: Event Communication Plans (Ben Harvey) 10:40-10:45: JASMIN Support Introduction (Matt, Alex and Fatima) 10:45-10:50: Research Software Engineer Introduction (Colin Sauze) 10:50-11:05: Around the Zoom room Introductions (Centre Coordinators) 11:05-11:30: Overview of the week (Jenny Mecking) 11:30-12:30: open video chat for help getting onto JASMIN, CANARI gws and jupyter notebooks 14:00-16:00: guided tutorial of example python scripts 16:30-17:00: highlights of the day March 5, 2024: 9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of known issues and good to knows 11:00: Zoom discussion: LE member selection for the forced-ocean experiments (Go to breakout room) 15:00: Zoom discussion: LE member selection for the forced-ocean experiments (Go to breakout room) 16:30-17:00: highlights of the day March 6, 2024: 9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of known issues and good to knows 16:30-17:00: highlights of the day (Scott Osprey) March 7, 2024: 9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of known issues and good to knows 16:30-17:00: highlights of the day (Len Shaffrey) March 8, 2024: 9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of known issues and good to knows 10:00-10:30: A group zoom screen shot will be done at the end of the good morning meeting 16:00-17:00: highlights of the week","title":"Sprint"},{"location":"sprint/#sprint","text":"The sprint will take place March 4-8, 2024 as a hybrid sprint, with each participating centre working together and then connecting to each other via zoom. The goal of the sprint is to work together to kickstart analysis on the CANARI-LE data.","title":"Sprint"},{"location":"sprint/#useful-links","text":"participants list CANARI sprint GitHub Repositories list of useful datasets on JASMIN list of analysis useful to multiple people priority variables and variable names CANARI-LE information","title":"Useful links"},{"location":"sprint/#schedule","text":"","title":"Schedule"},{"location":"sprint/#march-4-2024","text":"9:45: Zoom channel opens for the day 10:00-10:10: Good morning and Welcome (Jenny Mecking) 10:10-10:20: Overview of CANARI (Len Shaffrey) 10:20-10:35: CANARI-LE overview (Reinhard Schiemann) 10:35-10:40: Event Communication Plans (Ben Harvey) 10:40-10:45: JASMIN Support Introduction (Matt, Alex and Fatima) 10:45-10:50: Research Software Engineer Introduction (Colin Sauze) 10:50-11:05: Around the Zoom room Introductions (Centre Coordinators) 11:05-11:30: Overview of the week (Jenny Mecking) 11:30-12:30: open video chat for help getting onto JASMIN, CANARI gws and jupyter notebooks 14:00-16:00: guided tutorial of example python scripts 16:30-17:00: highlights of the day","title":"March 4, 2024:"},{"location":"sprint/#march-5-2024","text":"9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of known issues and good to knows 11:00: Zoom discussion: LE member selection for the forced-ocean experiments (Go to breakout room) 15:00: Zoom discussion: LE member selection for the forced-ocean experiments (Go to breakout room) 16:30-17:00: highlights of the day","title":"March 5, 2024:"},{"location":"sprint/#march-6-2024","text":"9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of known issues and good to knows 16:30-17:00: highlights of the day (Scott Osprey)","title":"March 6, 2024:"},{"location":"sprint/#march-7-2024","text":"9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of known issues and good to knows 16:30-17:00: highlights of the day (Len Shaffrey)","title":"March 7, 2024:"},{"location":"sprint/#march-8-2024","text":"9:45: Zoom channel opens for the day 10:00-10:30: Good morning, sharing of known issues and good to knows 10:00-10:30: A group zoom screen shot will be done at the end of the good morning meeting 16:00-17:00: highlights of the week","title":"March 8, 2024:"},{"location":"tutorials/","text":"Tutorials Some simple tutorials to get you started analysing the CANARI-LE. Git Setup and Basics Configuring and Using the JASMIN Notebooks Service Creating and Using your Own Conda/Mamba Enviroment Running on Sci Servers, installing Micromamba and running your own JupyterLab Using the Dask gateway Computing indices with cf-python CDFTOOLS : a diagnostic package written in fortran 90 for the analysis of NEMO model output, initialized in the frame of the DRAKKAR project (https://www.drakkar-ocean.eu/) Data Analysis Guides: Access our data analysis guides hosted on the tutorials repository . To try these tutorials independently, clone the repository in JASMIN with the following commands: git clone https://github.com/CANARI-sprint/tutorials.git cd tutorials !IMPORTANT: You need to have access to the CANARI gws. Here's a catalog of the available notebooks. The first 8 tutorials refer to the COAsT python package . 1) Basic Data Manipulation : Introduction to data handling using the COAsT package. 2) Exporting to NetCDF : Guide on exporting outputs to netCDF format for future use or analysis. 3) Climatology Tutorial : Demonstrates calculating climatological means and multi-year climatologies. 4) Calculating EOFs : How to utilize COAsT for computing Empirical Orthogonal Functions (EOFs). 5) Potential Energy Analysis : Tutorial on calculating Potential Energy Anomaly and applying regional masking.. 6) Pycnocline Diagnostics : Exploration of pycnocline depth and thickness diagnostics. 7) Seasonal Decomposition : Techniques for decomposing time series into trend, seasonal, and residual components. 8) Transect Calculations : Methods for creating data transects. 9) Basic Plots and Analysis : Utilizing CANARI-LE historical data for Sea Surface Temperature (SST) visualization. 10) UK Precipitation Plots : Making plots of UK precipitation using the iris python package, curtesy of Ben Harvey. 11) Box Profile Development : Computing ocean profiles with selected variables making use of the lotus queue on JASMIN.","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"Some simple tutorials to get you started analysing the CANARI-LE. Git Setup and Basics Configuring and Using the JASMIN Notebooks Service Creating and Using your Own Conda/Mamba Enviroment Running on Sci Servers, installing Micromamba and running your own JupyterLab Using the Dask gateway Computing indices with cf-python CDFTOOLS : a diagnostic package written in fortran 90 for the analysis of NEMO model output, initialized in the frame of the DRAKKAR project (https://www.drakkar-ocean.eu/) Data Analysis Guides: Access our data analysis guides hosted on the tutorials repository . To try these tutorials independently, clone the repository in JASMIN with the following commands: git clone https://github.com/CANARI-sprint/tutorials.git cd tutorials !IMPORTANT: You need to have access to the CANARI gws. Here's a catalog of the available notebooks. The first 8 tutorials refer to the COAsT python package . 1) Basic Data Manipulation : Introduction to data handling using the COAsT package. 2) Exporting to NetCDF : Guide on exporting outputs to netCDF format for future use or analysis. 3) Climatology Tutorial : Demonstrates calculating climatological means and multi-year climatologies. 4) Calculating EOFs : How to utilize COAsT for computing Empirical Orthogonal Functions (EOFs). 5) Potential Energy Analysis : Tutorial on calculating Potential Energy Anomaly and applying regional masking.. 6) Pycnocline Diagnostics : Exploration of pycnocline depth and thickness diagnostics. 7) Seasonal Decomposition : Techniques for decomposing time series into trend, seasonal, and residual components. 8) Transect Calculations : Methods for creating data transects. 9) Basic Plots and Analysis : Utilizing CANARI-LE historical data for Sea Surface Temperature (SST) visualization. 10) UK Precipitation Plots : Making plots of UK precipitation using the iris python package, curtesy of Ben Harvey. 11) Box Profile Development : Computing ocean profiles with selected variables making use of the lotus queue on JASMIN.","title":"Tutorials"},{"location":"using_the_dask_gateway/","text":"Using the Dask gateway What is Dask? Dask is a distributed computing framework for Python. It allows operations working on large datasets to be split across multiple computers (or multiple cores on the same computer). JASMIN offers a Dask gateway that allows jobs to run on up to 16 CPU cores on the Lotus cluster. This can be a convienient way to overcome the processor and memory limitations of the JASMIN notebook service, while still using that service to write and run your code. Requesting Access to the Dask Cluster Before using the Dask Cluster on JASMIN you must add it to your services. Please visit the additional services page on the JASMIN accounts portal This will need approval from the JASMIN staff and won't happen instantly. Configuring your Dask environment There are some extra packages that aren't in the main CANARI environment that you'll need to run Dask. We've added these to another environment in the group workspace called dask-env. To make the Dask enviroment visible to Jupyter Lab, in a terminal on the notebook service run: mamba run -p /gws/smf/j04/canari/dask-env python -m ipykernel install --user --name CANARI-dask . After about one minute a new icon called \"CANARI-dask\" should appear in the Jupyter launcher. If you have existing Dask code then see the JASMIN documentation for an example of how to configure it to use the Dask gateway or see the examples below. Running the examples There are two dask examples in the tutorials git repository. If you cloned the repository before these were added (end of March 6th) then you'll need to run a git pull operation to bring in the latest changes. In the files view in Jupyter Lab go to your copy of tutorials repository, click on the Git menu and choose \"Pull from Remote\". Or you can navigate to this directory in the terminal and type the command git pull . Two example files called dask-example1.ipynb and dask-example2.ipynb should appear. Open these, ensure they are using the CANARI-dask kernel and launch them. The first example demonstrates the Dask Delayed feature where calculations are not executed until their result is requested. The second example shows the futures feature where tasks are executed immediately, but anything wanting to access to the result will be forced to wait until the calculation is complete.","title":"Using the dask gateway"},{"location":"using_the_dask_gateway/#using-the-dask-gateway","text":"","title":"Using the Dask gateway"},{"location":"using_the_dask_gateway/#what-is-dask","text":"Dask is a distributed computing framework for Python. It allows operations working on large datasets to be split across multiple computers (or multiple cores on the same computer). JASMIN offers a Dask gateway that allows jobs to run on up to 16 CPU cores on the Lotus cluster. This can be a convienient way to overcome the processor and memory limitations of the JASMIN notebook service, while still using that service to write and run your code.","title":"What is Dask?"},{"location":"using_the_dask_gateway/#requesting-access-to-the-dask-cluster","text":"Before using the Dask Cluster on JASMIN you must add it to your services. Please visit the additional services page on the JASMIN accounts portal This will need approval from the JASMIN staff and won't happen instantly.","title":"Requesting Access to the Dask Cluster"},{"location":"using_the_dask_gateway/#configuring-your-dask-environment","text":"There are some extra packages that aren't in the main CANARI environment that you'll need to run Dask. We've added these to another environment in the group workspace called dask-env. To make the Dask enviroment visible to Jupyter Lab, in a terminal on the notebook service run: mamba run -p /gws/smf/j04/canari/dask-env python -m ipykernel install --user --name CANARI-dask . After about one minute a new icon called \"CANARI-dask\" should appear in the Jupyter launcher. If you have existing Dask code then see the JASMIN documentation for an example of how to configure it to use the Dask gateway or see the examples below.","title":"Configuring your Dask environment"},{"location":"using_the_dask_gateway/#running-the-examples","text":"There are two dask examples in the tutorials git repository. If you cloned the repository before these were added (end of March 6th) then you'll need to run a git pull operation to bring in the latest changes. In the files view in Jupyter Lab go to your copy of tutorials repository, click on the Git menu and choose \"Pull from Remote\". Or you can navigate to this directory in the terminal and type the command git pull . Two example files called dask-example1.ipynb and dask-example2.ipynb should appear. Open these, ensure they are using the CANARI-dask kernel and launch them. The first example demonstrates the Dask Delayed feature where calculations are not executed until their result is requested. The second example shows the futures feature where tasks are executed immediately, but anything wanting to access to the result will be forced to wait until the calculation is complete.","title":"Running the examples"}]}